# -*- coding: utf-8 -*-
"""Dicoding Submission One.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mOSX619IB_8bzjfA82pB7A4vCv6MdQAl
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
plt.rcParams['figure.dpi'] = 200

url = 'https://raw.githubusercontent.com/arima2515/Dicoding-Submission/main/Fish.csv'
fish = pd.read_csv(url)
fish.head()

fish.info()

fish.describe()

fish.isnull().sum()

fish.hist(figsize=(20, 15))

numerical_feature = fish._get_numeric_data().columns
categorical_feature = list(set(fish.columns) - set(numerical_feature))

for col in numerical_feature:
  print('===============================================================================================================================')
  plt.title('Persebaran kolom {}'.format(col))
  sns.boxplot(x=fish[col])
  plt.show()
  print('===============================================================================================================================\n')

Q1 = fish.quantile(0.25)
Q3 = fish.quantile(0.75)
IQR=Q3-Q1
fish=fish[~((fish<(Q1-1.5*IQR))|(fish>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
fish.shape

for categorical in categorical_feature:
  print('=====================================================================================================================================')
  count = fish[categorical].value_counts()
  percent = 100*fish[categorical].value_counts(normalize=True)
  df = pd.DataFrame({'jumlah sampel' : count, 'persentase' :percent.round(1)})
  print(df , '\n')
  count.plot(kind='bar', title=categorical)
  plt.show()
  print('=====================================================================================================================================\n')

for col in numerical_feature:
  sns.catplot(x='Species', y=col, data=fish, kind='bar', palette='Set3', dodge=False, height = 4, aspect = 3)
  plt.title("Rata-rata {} Relatif terhadap - 'Species'".format(col))
  plt.figure(figsize=(15, 10))
  plt.show()
  print()

sns.pairplot(fish, diag_kind='kde')

plt.figure(figsize=(25, 25))
sns.heatmap(data=fish.corr(), annot=True, cmap='coolwarm')
plt.title('Hubungan antara data dengan variabel target prediksi')

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in categorical_column:
  fish[col] = le.fit_transform(fish[col])
fish.head()

X = fish.drop(['Species'], axis=1)
y = fish['Species']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=24)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
feature = numerical_feature
X_train[feature] = sc.fit_transform(X_train[feature])
X_test[feature] = sc.fit_transform(X_test[feature])

X_train.describe()

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'DeepLearning'])

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

from sklearn.ensemble import RandomForestRegressor
 
RF = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=24, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense

DL = tf.keras.Sequential([
    Dense(50, input_shape=[6], activation='relu'),
    Dense(100, activation='relu'),
    Dense(100, activation='relu'),
    Dense(1)
])

optimizer = Adam(learning_rate=1e-3)

DL.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])

DL.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=1)

models.loc['train_mse','DeepLearning'] = mean_squared_error(y_pred=DL.predict(X_train), y_true=y_train)

X_test.loc[:, feature] = sc.transform(X_test[feature])

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','DL'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'DL': DL}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi)[0].round(0).astype(int)
 
pd.DataFrame(pred_dict)